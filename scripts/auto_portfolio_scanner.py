#!/usr/bin/env python3
"""
ìë™ í¬íŠ¸í´ë¦¬ì˜¤ ìŠ¤ìºë„ˆ
GitHub APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ ë ˆí¬ì§€í† ë¦¬ì™€ ë°°í¬ë¥¼ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³  portfolio ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
"""

import os
import json
import requests
import time
from datetime import datetime, timezone
from typing import Dict, List, Any, Optional

class AutoPortfolioScanner:
    def __init__(self):
        self.github_token = os.environ.get('GITHUB_TOKEN')
        if not self.github_token:
            raise ValueError("GITHUB_TOKEN environment variable is required")
        
        self.username = "yonghwan1106"
        self.headers = {
            'Authorization': f'token {self.github_token}',
            'Accept': 'application/vnd.github.v3+json'
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        
    def get_all_repositories(self) -> List[Dict]:
        """GitHub APIë¡œ ëª¨ë“  ë ˆí¬ì§€í† ë¦¬ ê°€ì ¸ì˜¤ê¸°"""
        repos = []
        page = 1
        per_page = 100
        
        while True:
            url = f"https://api.github.com/users/{self.username}/repos"
            params = {
                'page': page,
                'per_page': per_page,
                'sort': 'updated',
                'direction': 'desc'
            }
            
            response = self.session.get(url, params=params)
            if response.status_code != 200:
                print(f"Error fetching repositories: {response.status_code}")
                break
                
            page_repos = response.json()
            if not page_repos:
                break
                
            repos.extend(page_repos)
            page += 1
            
            # API ë ˆì´íŠ¸ ë¦¬ë°‹ ë°©ì§€
            time.sleep(0.1)
            
        return repos
    
    def auto_categorize(self, repo_name: str, description: str) -> str:
        """ë ˆí¬ì§€í† ë¦¬ëª…ê³¼ ì„¤ëª…ì„ ë¶„ì„í•˜ì—¬ ìë™ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        name_lower = repo_name.lower()
        desc_lower = description.lower()
        text = f"{name_lower} {desc_lower}"
        
        # ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ ë§¤í•‘
        category_keywords = {
            'AI/ë””ì§€í„¸': ['ai', 'smart', 'digital', 'platform', 'tech', 'data', 'startup', 'innovation'],
            'í™˜ê²½': ['carbon', 'eco', 'energy', 'marine', 'environment', 'green', 'climate'],
            'ë†ì—…': ['agriculture', 'farm', 'agri', 'food', 'crop'],
            'ì•ˆì „': ['safety', 'security', 'emergency', 'protection'],
            'ê´€ê´‘': ['tourism', 'travel', 'tourist', 'heritage', 'culture'],
            'ì²­ë…„': ['youth', 'young', 'student', 'startup'],
            'ì§€ìì²´': ['city', 'county', 'district', 'local', 'municipal', 'policy', 'government'],
            'ê·œì œí˜ì‹ ': ['regulation', 'deregulation', 'reform', 'policy'],
            'ë¬¸í™”': ['culture', 'heritage', 'art', 'museum', 'festival']
        }
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ ê²°ì •
        for category, keywords in category_keywords.items():
            for keyword in keywords:
                if keyword in text:
                    return category
        
        return 'ê¸°íƒ€'
    
    def check_deployment_url(self, url: str) -> Dict[str, Any]:
        """URL ì ‘ê·¼ ê°€ëŠ¥ì„± í™•ì¸"""
        try:
            response = requests.get(url, timeout=10, allow_redirects=True)
            return {
                'status': 'live' if response.status_code == 200 else 'error',
                'response_code': response.status_code,
                'content_length': len(response.content) if response.status_code == 200 else 0
            }
        except Exception as e:
            return {
                'status': 'not_found',
                'response_code': None,
                'error': str(e)
            }
    
    def scan_repository_deployments(self, repo: Dict) -> Dict[str, Any]:
        """ê°œë³„ ë ˆí¬ì§€í† ë¦¬ì˜ ë°°í¬ ìƒíƒœ ìŠ¤ìº”"""
        repo_name = repo['name']
        deployments = []
        platforms = {}
        
        # GitHub Pages í™•ì¸
        github_pages_url = f"https://{self.username}.github.io/{repo_name}/"
        github_status = self.check_deployment_url(github_pages_url)
        platforms['github'] = {
            'url': github_pages_url if github_status['status'] == 'live' else '',
            'status': github_status['status'],
            'response_code': github_status.get('response_code')
        }
        
        if github_status['status'] == 'live':
            deployments.append({
                'platform': 'github_pages',
                'url': github_pages_url,
                'response_code': github_status['response_code'],
                'content_length': github_status.get('content_length', 0)
            })
        
        # Vercel í™•ì¸
        vercel_url = f"https://{repo_name}.vercel.app/"
        vercel_status = self.check_deployment_url(vercel_url)
        platforms['vercel'] = {
            'url': vercel_url if vercel_status['status'] == 'live' else '',
            'status': vercel_status['status'],
            'response_code': vercel_status.get('response_code')
        }
        
        if vercel_status['status'] == 'live':
            deployments.append({
                'platform': 'vercel',
                'url': vercel_url,
                'response_code': vercel_status['response_code'],
                'content_length': vercel_status.get('content_length', 0)
            })
        
        # Render í™•ì¸
        render_url = f"https://{repo_name}.onrender.com/"
        render_status = self.check_deployment_url(render_url)
        platforms['render'] = {
            'url': render_url if render_status['status'] == 'live' else '',
            'status': render_status['status'],
            'response_code': render_status.get('response_code')
        }
        
        if render_status['status'] == 'live':
            deployments.append({
                'platform': 'render',
                'url': render_url,
                'response_code': render_status['response_code'],
                'content_length': render_status.get('content_length', 0)
            })
        
        # ì£¼ìš” ë°°í¬ URL ê²°ì •
        primary_url = ''
        primary_platform = ''
        if deployments:
            # ìš°ì„ ìˆœìœ„: Vercel > GitHub Pages > Render
            for platform in ['vercel', 'github_pages', 'render']:
                for deployment in deployments:
                    if deployment['platform'] == platform:
                        primary_url = deployment['url']
                        primary_platform = platform
                        break
                if primary_url:
                    break
        
        # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        quality_score = 50  # ê¸°ë³¸ ì ìˆ˜
        if deployments:
            quality_score += 20  # ë°°í¬ ê°€ëŠ¥í•œ í”„ë¡œì íŠ¸
        if len(deployments) > 1:
            quality_score += 10  # ë‹¤ì¤‘ í”Œë«í¼ ë°°í¬
        if repo.get('stargazers_count', 0) > 0:
            quality_score += 10  # ìŠ¤íƒ€ê°€ ìˆëŠ” í”„ë¡œì íŠ¸
        if repo.get('description'):
            quality_score += 5   # ì„¤ëª…ì´ ìˆëŠ” í”„ë¡œì íŠ¸
        
        quality_score = min(quality_score, 95)  # ìµœëŒ€ 95ì 
        
        # ìë™ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
        category = self.auto_categorize(repo_name, repo.get('description', ''))
        
        return {
            'id': repo_name,
            'name': repo_name,
            'scan_date': datetime.now(timezone.utc).isoformat(),
            'deployments': deployments,
            'platforms': platforms,
            'total_deployments': len(deployments),
            'primary_url': primary_url,
            'primary_platform': primary_platform,
            'is_live': len(deployments) > 0,
            'category': category,
            'title': repo_name,
            'description': repo.get('description', ''),
            'github_url': repo['html_url'],
            'quality_score': quality_score,
            'stars': repo.get('stargazers_count', 0),
            'updated_at': repo.get('updated_at', ''),
            'created_at': repo.get('created_at', '')
        }
    
    def load_existing_data(self) -> Dict:
        """ê¸°ì¡´ í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„° ë¡œë“œ"""
        try:
            with open('projects_scan_result_final.json', 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            return {
                'scan_info': {
                    'scan_date': datetime.now(timezone.utc).isoformat(),
                    'total_projects': 0,
                    'scanner_version': '3.0'
                },
                'projects': []
            }
    
    def save_data(self, data: Dict):
        """í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„° ì €ì¥"""
        with open('projects_scan_result_final.json', 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    def run_scan(self):
        """ì „ì²´ ìŠ¤ìº” ì‹¤í–‰"""
        print("ğŸš€ Starting automatic portfolio scan...")
        
        # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
        existing_data = self.load_existing_data()
        existing_projects = {p['name']: p for p in existing_data.get('projects', [])}
        
        # GitHub ë ˆí¬ì§€í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
        print("ğŸ“¡ Fetching repositories from GitHub API...")
        repos = self.get_all_repositories()
        print(f"Found {len(repos)} repositories")
        
        new_projects = []
        live_count = 0
        
        for i, repo in enumerate(repos, 1):
            repo_name = repo['name']
            print(f"[{i}/{len(repos)}] Scanning {repo_name}...")
            
            # ë ˆí¬ì§€í† ë¦¬ ìŠ¤ìº”
            project_data = self.scan_repository_deployments(repo)
            
            # ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ íŠ¹ì • í•„ë“œ ìœ ì§€
            if repo_name in existing_projects:
                existing = existing_projects[repo_name]
                # ìˆ˜ë™ìœ¼ë¡œ ì„¤ì •ëœ ì •ë³´ëŠ” ìœ ì§€
                project_data['category'] = existing.get('category', 'ê¸°íƒ€')
                if existing.get('title') != existing.get('name'):
                    project_data['title'] = existing['title']
                if existing.get('description') and existing['description'] != repo.get('description', ''):
                    project_data['description'] = existing['description']
            
            if project_data['is_live']:
                new_projects.append(project_data)
                live_count += 1
                print(f"  âœ… Live deployments: {project_data['total_deployments']}")
            
            # API ë ˆì´íŠ¸ ë¦¬ë°‹ ë°©ì§€
            time.sleep(0.2)
        
        # ê²°ê³¼ ì €ì¥
        result_data = {
            'scan_info': {
                'scan_date': datetime.now(timezone.utc).isoformat(),
                'total_projects': live_count,
                'scanner_version': '3.0',
                'auto_scan': True
            },
            'projects': new_projects
        }
        
        self.save_data(result_data)
        
        print(f"\nâœ… Scan completed!")
        print(f"ğŸ“Š Total repositories: {len(repos)}")
        print(f"ğŸš€ Live deployments: {live_count}")
        print(f"ğŸ’¾ Data saved to projects_scan_result_final.json")
        
        return live_count

if __name__ == '__main__':
    try:
        scanner = AutoPortfolioScanner()
        scanner.run_scan()
    except Exception as e:
        print(f"âŒ Error: {e}")
        exit(1)